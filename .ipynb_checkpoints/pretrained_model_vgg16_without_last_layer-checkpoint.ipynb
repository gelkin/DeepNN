{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "# from keras.applications import ResNet50\n",
    "# todo: without these models so far\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception # TensorFlow ONLY\n",
    "from keras.applications import VGG16\n",
    "# from keras.applications import VGG19\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import h5py\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a dictionary that maps model names to their classes\n",
    "# inside Keras\n",
    "MODELS = {\n",
    "    \"vgg16\": VGG16,\n",
    "    \"vgg19\": VGG19,\n",
    "#     todo without these models so far\n",
    "#     \"inception\": InceptionV3,\n",
    "#     \"xception\": Xception, # TensorFlow ONLY\n",
    "    \"resnet\": ResNet50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputShape = (224, 224)\n",
    "preprocess = imagenet_utils.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_model = \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading vgg16...\n"
     ]
    }
   ],
   "source": [
    "# print(\"[INFO] loading {}...\".format(chosen_model))\n",
    "# Network = MODELS[chosen_model]\n",
    "# model = Network(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from scipy.misc import imread\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from scipy.misc import imresize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_path = os.getcwd() + \"\\\\\" + os.path.join( \"data\", \"labels.csv\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vladamir Mazin\\\\DeepNN\\\\data\\\\labels.csv\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_labels = pd.read_csv(labels_path + \"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(100, 2))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(data_labels):\n",
    "    msk = np.random.rand(len(data_labels)) < 0.8\n",
    "    train = data_labels[msk]\n",
    "    test = data_labels[~msk]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = get_train_test(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = os.getcwd() + \"\\\\\" + os.path.join( \"data\", \"train\", \"train\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing the train dataset\n",
    "train_img = []\n",
    "for row in train.iterrows():\n",
    "    temp_img = image.load_img(img_path + row[1]['id'] + '.jpg', target_size=(224,224))\n",
    "    temp_img = image.img_to_array(temp_img)\n",
    "    train_img.append(temp_img)\n",
    "    \n",
    "#converting train images to array and applying mean subtraction processing\n",
    "train_img = np.array(train_img) \n",
    "train_img = preprocess_input(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying the same procedure with the test dataset\n",
    "test_img=[]\n",
    "for row in test.iterrows():\n",
    "    temp_img = image.load_img(img_path + row[1]['id'] + '.jpg', target_size=(224,224))\n",
    "    temp_img = image.img_to_array(temp_img)\n",
    "    test_img.append(temp_img)\n",
    "\n",
    "test_img=np.array(test_img) \n",
    "test_img=preprocess_input(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading VGG16 model weights\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Extracting features from the train dataset using the VGG16 pre-trained model\n",
    "features_train = model.predict(train_img)\n",
    "\n",
    "# Extracting features from the test dataset using the VGG16 pre-trained model\n",
    "features_test=model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8182, 7, 7, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flattening the layers to conform to MLP input\n",
    "train_x = features_train.reshape(8182, 25088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting target variable to array\n",
    "train_y = np.asarray(train['breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performing one-hot encoding for the target variable\n",
    "train_y = pd.get_dummies(train_y)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8182, 120)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a mlp model\n",
    "from keras.layers import Dense, Activation\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(5000, input_dim=25088, activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1000,input_dim=5000,activation='sigmoid'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(500,input_dim=1000,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=120))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=128,validation_data=(X_valid,Y_valid))\n",
    "\n",
    "# todo - see Statistics.ipynb for the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "# model.fit(X_train, Y_train, epochs=20, batch_size=32,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

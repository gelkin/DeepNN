{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from scipy.misc import imread\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = os.getcwd() + \"\\\\\" + os.path.join( \"data\", \"labels.csv\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vladamir Mazin\\\\DeepNN\\\\data\\\\labels.csv\\\\'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = pd.read_csv(labels_path + \"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(100, 2))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_test(data_labels):\n",
    "#     msk = np.random.rand(len(data_labels)) < 0.8\n",
    "#     train = data_labels[msk]\n",
    "#     test = data_labels[~msk]\n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = get_train_test(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.getcwd() + \"\\\\\" + os.path.join( \"data\", \"train\", \"train\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import islice\n",
    "# for x in islice(train.iterrows(), 10):\n",
    "#     print(x[1]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preparing the train dataset\n",
    "# train_img = []\n",
    "# for row in train.iterrows():\n",
    "#     temp_img = image.load_img(img_path + row[1]['id'] + '.jpg', target_size=(224,224))\n",
    "#     temp_img = image.img_to_array(temp_img)\n",
    "#     train_img.append(temp_img)\n",
    "    \n",
    "# #converting train images to array and applying mean subtraction processing\n",
    "# train_img = np.array(train_img) \n",
    "# train_img = preprocess_input(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # applying the same procedure with the test dataset\n",
    "# test_img=[]\n",
    "# for row in test.iterrows():\n",
    "#     temp_img = image.load_img(img_path + row[1]['id'] + '.jpg', target_size=(224,224))\n",
    "#     temp_img = image.img_to_array(temp_img)\n",
    "#     test_img.append(temp_img)\n",
    "\n",
    "# test_img=np.array(test_img) \n",
    "# test_img=preprocess_input(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's consider all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # applying the same procedure with the test dataset\n",
    "# train_img = []\n",
    "# cnt = 1\n",
    "# for row in train.iterrows():\n",
    "#     temp_img = image.load_img(img_path + row[1]['id'] + '.jpg', target_size=(224,224))\n",
    "#     temp_img = image.img_to_array(temp_img)\n",
    "#     train_img.append(temp_img)\n",
    "#     if cnt % 100 == 0:\n",
    "#         print(\"{} images processed\".format(cnt))\n",
    "#     cnt += 1\n",
    "# train_img = np.array(train_img) \n",
    "# train_img = preprocess_input(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "def vgg16_model(img_rows, img_cols, channel=1, num_classes=None, num_layers_to_keep=8):\n",
    "    model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "    model.layers.pop()\n",
    "\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "\n",
    "    x=Dense(num_classes, activation='softmax')(model.output)\n",
    "\n",
    "    model=Model(model.input,x)\n",
    "\n",
    "    #To set the first 8 layers to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:num_layers_to_keep]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.asarray(train['breed'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_y = le.fit_transform(train_y)\n",
    "\n",
    "train_y=to_categorical(train_y)\n",
    "\n",
    "train_y=np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2045, 224, 224, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to fine-tune on 3000 samples from Cifar10\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 120 \n",
    "batch_size = 32\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               120120    \n",
      "=================================================================\n",
      "Total params: 138,477,664\n",
      "Trainable params: 137,922,336\n",
      "Non-trainable params: 555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load our model\n",
    "model_8_pretrained_layers = vgg16_model(img_rows, img_cols, channel, num_classes)\n",
    "model_8_pretrained_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/10\n",
      "8177/8177 [==============================] - 172s 21ms/step - loss: 4.7779 - acc: 0.0353 - val_loss: 4.7672 - val_acc: 0.0826\n",
      "Epoch 2/10\n",
      "8177/8177 [==============================] - 149s 18ms/step - loss: 4.7569 - acc: 0.1419 - val_loss: 4.7520 - val_acc: 0.1658\n",
      "Epoch 3/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.7415 - acc: 0.2059 - val_loss: 4.7398 - val_acc: 0.2166\n",
      "Epoch 4/10\n",
      "8177/8177 [==============================] - 149s 18ms/step - loss: 4.7268 - acc: 0.2637 - val_loss: 4.7260 - val_acc: 0.2724\n",
      "Epoch 5/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.7112 - acc: 0.3233 - val_loss: 4.7130 - val_acc: 0.3007\n",
      "Epoch 6/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.6960 - acc: 0.3477 - val_loss: 4.7011 - val_acc: 0.3178\n",
      "Epoch 7/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.6806 - acc: 0.3686 - val_loss: 4.6881 - val_acc: 0.3355\n",
      "Epoch 8/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.6647 - acc: 0.3853 - val_loss: 4.6713 - val_acc: 0.3467\n",
      "Epoch 9/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.6485 - acc: 0.4019 - val_loss: 4.6590 - val_acc: 0.3614\n",
      "Epoch 10/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.6324 - acc: 0.4113 - val_loss: 4.6440 - val_acc: 0.3682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d24cf376a0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Fine-tuning\n",
    "model_8_pretrained_layers.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,\n",
    "                              shuffle=True,verbose=1,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/10\n",
      "8177/8177 [==============================] - 188s 23ms/step - loss: 4.6160 - acc: 0.4138 - val_loss: 4.6296 - val_acc: 0.3731\n",
      "Epoch 2/10\n",
      "8177/8177 [==============================] - 169s 21ms/step - loss: 4.5979 - acc: 0.4222 - val_loss: 4.6139 - val_acc: 0.3907\n",
      "Epoch 3/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.5805 - acc: 0.4322 - val_loss: 4.6010 - val_acc: 0.3883\n",
      "Epoch 4/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.5632 - acc: 0.4431 - val_loss: 4.5868 - val_acc: 0.3917\n",
      "Epoch 5/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.5461 - acc: 0.4494 - val_loss: 4.5710 - val_acc: 0.4137\n",
      "Epoch 6/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.5282 - acc: 0.4670 - val_loss: 4.5629 - val_acc: 0.4064\n",
      "Epoch 7/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.5088 - acc: 0.4767 - val_loss: 4.5408 - val_acc: 0.4176\n",
      "Epoch 8/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.4917 - acc: 0.4788 - val_loss: 4.5316 - val_acc: 0.4112\n",
      "Epoch 9/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.4757 - acc: 0.4809 - val_loss: 4.5156 - val_acc: 0.4166\n",
      "Epoch 10/10\n",
      "8177/8177 [==============================] - 148s 18ms/step - loss: 4.4558 - acc: 0.4880 - val_loss: 4.5049 - val_acc: 0.4108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d24cf37208>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Fine-tuning\n",
    "model_8_pretrained_layers.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,\n",
    "                              shuffle=True,verbose=1,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Fine-tuning\n",
    "# model.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,shuffle=True,verbose=1,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try model with [2 more conv layers] that is leaving 8 + 3 + 4 = 15 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               120120    \n",
      "=================================================================\n",
      "Total params: 138,477,664\n",
      "Trainable params: 130,842,400\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load our model\n",
    "model_15_pretrained_layers = vgg16_model(img_rows, img_cols, channel, num_classes, num_layers_to_keep=15)\n",
    "model_15_pretrained_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/10\n",
      "8177/8177 [==============================] - 112s 14ms/step - loss: 4.7829 - acc: 0.0212 - val_loss: 4.7729 - val_acc: 0.0489\n",
      "Epoch 2/10\n",
      "8177/8177 [==============================] - 102s 12ms/step - loss: 4.7640 - acc: 0.0805 - val_loss: 4.7585 - val_acc: 0.1086\n",
      "Epoch 3/10\n",
      "8177/8177 [==============================] - 101s 12ms/step - loss: 4.7492 - acc: 0.1479 - val_loss: 4.7466 - val_acc: 0.1692\n",
      "Epoch 4/10\n",
      "8177/8177 [==============================] - 101s 12ms/step - loss: 4.7348 - acc: 0.1924 - val_loss: 4.7352 - val_acc: 0.2083\n",
      "Epoch 5/10\n",
      "8177/8177 [==============================] - 100s 12ms/step - loss: 4.7211 - acc: 0.2555 - val_loss: 4.7226 - val_acc: 0.2543\n",
      "Epoch 6/10\n",
      "8177/8177 [==============================] - 101s 12ms/step - loss: 4.7068 - acc: 0.2819 - val_loss: 4.7105 - val_acc: 0.2733\n",
      "Epoch 7/10\n",
      "8177/8177 [==============================] - 111s 14ms/step - loss: 4.6924 - acc: 0.3050 - val_loss: 4.6981 - val_acc: 0.2807\n",
      "Epoch 8/10\n",
      "8177/8177 [==============================] - 126s 15ms/step - loss: 4.6776 - acc: 0.3242 - val_loss: 4.6864 - val_acc: 0.2895\n",
      "Epoch 9/10\n",
      "8177/8177 [==============================] - 127s 16ms/step - loss: 4.6628 - acc: 0.3414 - val_loss: 4.6740 - val_acc: 0.3139\n",
      "Epoch 10/10\n",
      "7008/8177 [========================>.....] - ETA: 15s - loss: 4.6490 - acc: 0.3564"
     ]
    }
   ],
   "source": [
    "# Start Fine-tuning\n",
    "model_15_pretrained_layers.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,\n",
    "                               shuffle=True,verbose=1,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2045/2045 [==============================] - 17s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss score\n",
    "score = log_loss(Y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7878120063278082"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
